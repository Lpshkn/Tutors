{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bf1698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ae2218",
   "metadata": {},
   "source": [
    "# Загрузка и препроцессинг данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e29437",
   "metadata": {},
   "source": [
    "Нейросети не работают с сырыми даными по типу JPEG или CSV. Вместо этого они оперируют **векторами** и **специальными** представлениями:\n",
    "* Текстовые файлы должны быть прочитаны, строки получены и разбиты на слова. Слова должны быть проиндексированы и превращены в целочисленные тензоры.\n",
    "* Изображения должны быть так же прочитаны и преобразованы в тензоры пикселей (целочисленные), а затем нормализованы до некоторых маленьких значений (часто 0-1).\n",
    "* Табличные данные должны быть обработаны: категоризованные признаки должны быть приведены в целочисленные тензоры, а признаки в виде чисел с плавающей точкой преобразованы в соответствующие тензоры с плавающей точкой. В конце все признаки точно так же должны быть нормализованы, т.к. этого требуют модели.\n",
    "* Ну и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9fc560",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5b2813",
   "metadata": {},
   "source": [
    "Собственно, Keras оперирует тремя типами \"входов\" (или входных данных):\n",
    "* NumPy массивами (те самые `ndarray`), точно так же, как это делает sklearn. Это хороший вариант, если все данные умещаются в RAM.\n",
    "* Tensorflow Dataset объекты. Это вариант подходит для тех случаев, когда данные не помещаются в память и будут считывать либо с диска, либо вообще с распределенной ФС.\n",
    "* Питоновские генераторы, которые отдают пакеты данных (очевидно,  всё, что реализовано как генератор, может передаваться в Keras)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873d9268",
   "metadata": {},
   "source": [
    "Важно отметить, что если датасет правда большой, а вы собираетесь обучать модель на GPU, то стоит использовать объект Tensorflow Dataset, т.к. он обеспечивает высокую производительность засчёт:\n",
    "* ассинхронной предобработки данных на CPU, пока GPU загружена, и постановка предобработанных данных в очередь\n",
    "* поставки данных в GPU память так, что она немедленно становится доступна для GPU в момент, когда он прекратил обработку предыдущего поднабора данных. Это позволяет использовать GPU на полную."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab09f6c",
   "metadata": {},
   "source": [
    "Keras позволяет использовать ряд утилит для загрузки сырых данных с диска и превращения их сразу в объект `Dataset`:\n",
    "* `tf.keras.preprocessing.image_dataset_from_directory` - для превращения изображений, отсортированных по специальной классовой структуре (в виде структуры папок) в размеченный датасет тензоров изображений.\n",
    "* `tf.keras.preprocessing.text_dataset_from_directory` - то же самое, но для текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a8f8e5",
   "metadata": {},
   "source": [
    "Как пример просто загрузим [вот этот датасет](https://www.kaggle.com/olgabelitskaya/tomato-cultivars) и распределим его по директориям (каждая директория представляет собой отдельный конкретный класс). Теперь можем воспользоваться методом выше, чтобы автоматически создать размеченный датасет из структуры папок.\n",
    "\n",
    "Моя структура папок:\n",
    "```\n",
    "Tomato Cultivars/\n",
    "...tomato_1/\n",
    "......01_001.png\n",
    "......01_002.png\n",
    "................\n",
    "...tomato_2/\n",
    "......02_001.png\n",
    "......02_002.png\n",
    "................\n",
    "............\n",
    "...tomato_15/\n",
    "......15_001.png\n",
    "......15_002.png\n",
    "................\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39f45d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_directory = '/home/lpshkn/Datasets/Tomato Cultivars/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "511f5e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 776 files belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset = keras.preprocessing.image_dataset_from_directory(main_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68328514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tomato_1',\n",
       " 'tomato_10',\n",
       " 'tomato_11',\n",
       " 'tomato_12',\n",
       " 'tomato_13',\n",
       " 'tomato_14',\n",
       " 'tomato_15',\n",
       " 'tomato_2',\n",
       " 'tomato_3',\n",
       " 'tomato_4',\n",
       " 'tomato_5',\n",
       " 'tomato_6',\n",
       " 'tomato_7',\n",
       " 'tomato_8',\n",
       " 'tomato_9']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6900435",
   "metadata": {},
   "source": [
    "Как можно заметить, это идеально подходит для случаев, когда данных в виде текстовых или изображений очень много и все они разбросаны по директориям. Тогда можно написать простой bash скрипт, уложив всё по папкам, и использовать эти функции."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e4fe52",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b11d6c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
